{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations in Political Economy - Technological Change and Populism (POL63102)\n",
    "### Coding Session 2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "This document guides you through coding session 2. Please try to follow the instructions on your own PC and feel free to ask questions if something is unclear. After this session you should be able to do the following:\n",
    "\n",
    "- Implement Simple Linear Regression in Python\n",
    "- Interprete Results from Simple Linear Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules and Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a standard tool for analyzing the relationship between two or more variables.\n",
    "\n",
    "Let's start with importing the modules needed for our analysis. In addition to **pandas**, **seaborn**, and **matplotlib**, we will also use **numpy** for numerical calculus and **statsmodels** to estimate, interpret, and visualize linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Coding Session 1, let's use the data from Autor et al. (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('C:/Users/felix/Dropbox/HfP/Teaching/SoSe21/Populism_Course/data/Autor_data_extract.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question in the paper is whether higher import competition leads to higher vote shares for the Republican party in the 2016 election as compared to the 2002 election. Thus, we can write a simple linear regression model as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta \\text{Republican Vote Share}_i = \\beta_0 + \\beta_1 \\text{Import Competition}_i + u_i\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "* $i$ indexes observations (county-district cells in the US)\n",
    "* $\\beta_0$ is the intercept of the linear trend line on the y-axis\n",
    "* $\\beta_1$ is the slope of the linear trend line, representing the marginal effect of a unit change in $\\text{Import Competition}_i$ on $\\Delta \\text{Republican Vote Share}_i$\n",
    "* $u_i$ is the error term (deviations of observations from the linear trend due to factors not included in the model)\n",
    "\n",
    "Let's first visualise this regression by overlaying a scatterplot with a linear fit using the *regplot()* function from **seaborn**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function regplot in module seaborn.regression:\n",
      "\n",
      "regplot(x, y, data=None, x_estimator=None, x_bins=None, x_ci='ci', scatter=True, fit_reg=True, ci=95, n_boot=1000, units=None, order=1, logistic=False, lowess=False, robust=False, logx=False, x_partial=None, y_partial=None, truncate=False, dropna=True, x_jitter=None, y_jitter=None, label=None, color=None, marker='o', scatter_kws=None, line_kws=None, ax=None)\n",
      "    Plot data and a linear regression model fit.\n",
      "    \n",
      "    There are a number of mutually exclusive options for estimating the\n",
      "    regression model. See the :ref:`tutorial <regression_tutorial>` for more\n",
      "    information.    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x, y: string, series, or vector array\n",
      "        Input variables. If strings, these should correspond with column names\n",
      "        in ``data``. When pandas objects are used, axes will be labeled with\n",
      "        the series name.\n",
      "    data : DataFrame\n",
      "        Tidy (\"long-form\") dataframe where each column is a variable and each\n",
      "        row is an observation.    \n",
      "    x_estimator : callable that maps vector -> scalar, optional\n",
      "        Apply this function to each unique value of ``x`` and plot the\n",
      "        resulting estimate. This is useful when ``x`` is a discrete variable.\n",
      "        If ``x_ci`` is given, this estimate will be bootstrapped and a\n",
      "        confidence interval will be drawn.    \n",
      "    x_bins : int or vector, optional\n",
      "        Bin the ``x`` variable into discrete bins and then estimate the central\n",
      "        tendency and a confidence interval. This binning only influences how\n",
      "        the scatterplot is drawn; the regression is still fit to the original\n",
      "        data.  This parameter is interpreted either as the number of\n",
      "        evenly-sized (not necessary spaced) bins or the positions of the bin\n",
      "        centers. When this parameter is used, it implies that the default of\n",
      "        ``x_estimator`` is ``numpy.mean``.    \n",
      "    x_ci : \"ci\", \"sd\", int in [0, 100] or None, optional\n",
      "        Size of the confidence interval used when plotting a central tendency\n",
      "        for discrete values of ``x``. If ``\"ci\"``, defer to the value of the\n",
      "        ``ci`` parameter. If ``\"sd\"``, skip bootstrapping and show the\n",
      "        standard deviation of the observations in each bin.    \n",
      "    scatter : bool, optional\n",
      "        If ``True``, draw a scatterplot with the underlying observations (or\n",
      "        the ``x_estimator`` values).    \n",
      "    fit_reg : bool, optional\n",
      "        If ``True``, estimate and plot a regression model relating the ``x``\n",
      "        and ``y`` variables.    \n",
      "    ci : int in [0, 100] or None, optional\n",
      "        Size of the confidence interval for the regression estimate. This will\n",
      "        be drawn using translucent bands around the regression line. The\n",
      "        confidence interval is estimated using a bootstrap; for large\n",
      "        datasets, it may be advisable to avoid that computation by setting\n",
      "        this parameter to None.    \n",
      "    n_boot : int, optional\n",
      "        Number of bootstrap resamples used to estimate the ``ci``. The default\n",
      "        value attempts to balance time and stability; you may want to increase\n",
      "        this value for \"final\" versions of plots.    \n",
      "    units : variable name in ``data``, optional\n",
      "        If the ``x`` and ``y`` observations are nested within sampling units,\n",
      "        those can be specified here. This will be taken into account when\n",
      "        computing the confidence intervals by performing a multilevel bootstrap\n",
      "        that resamples both units and observations (within unit). This does not\n",
      "        otherwise influence how the regression is estimated or drawn.    \n",
      "    order : int, optional\n",
      "        If ``order`` is greater than 1, use ``numpy.polyfit`` to estimate a\n",
      "        polynomial regression.    \n",
      "    logistic : bool, optional\n",
      "        If ``True``, assume that ``y`` is a binary variable and use\n",
      "        ``statsmodels`` to estimate a logistic regression model. Note that this\n",
      "        is substantially more computationally intensive than linear regression,\n",
      "        so you may wish to decrease the number of bootstrap resamples\n",
      "        (``n_boot``) or set ``ci`` to None.    \n",
      "    lowess : bool, optional\n",
      "        If ``True``, use ``statsmodels`` to estimate a nonparametric lowess\n",
      "        model (locally weighted linear regression). Note that confidence\n",
      "        intervals cannot currently be drawn for this kind of model.    \n",
      "    robust : bool, optional\n",
      "        If ``True``, use ``statsmodels`` to estimate a robust regression. This\n",
      "        will de-weight outliers. Note that this is substantially more\n",
      "        computationally intensive than standard linear regression, so you may\n",
      "        wish to decrease the number of bootstrap resamples (``n_boot``) or set\n",
      "        ``ci`` to None.    \n",
      "    logx : bool, optional\n",
      "        If ``True``, estimate a linear regression of the form y ~ log(x), but\n",
      "        plot the scatterplot and regression model in the input space. Note that\n",
      "        ``x`` must be positive for this to work.    \n",
      "    {x,y}_partial : strings in ``data`` or matrices\n",
      "        Confounding variables to regress out of the ``x`` or ``y`` variables\n",
      "        before plotting.    \n",
      "    truncate : bool, optional\n",
      "        By default, the regression line is drawn to fill the x axis limits\n",
      "        after the scatterplot is drawn. If ``truncate`` is ``True``, it will\n",
      "        instead by bounded by the data limits.    \n",
      "    {x,y}_jitter : floats, optional\n",
      "        Add uniform random noise of this size to either the ``x`` or ``y``\n",
      "        variables. The noise is added to a copy of the data after fitting the\n",
      "        regression, and only influences the look of the scatterplot. This can\n",
      "        be helpful when plotting variables that take discrete values.    \n",
      "    label : string\n",
      "        Label to apply to ether the scatterplot or regression line (if\n",
      "        ``scatter`` is ``False``) for use in a legend.\n",
      "    color : matplotlib color\n",
      "        Color to apply to all plot elements; will be superseded by colors\n",
      "        passed in ``scatter_kws`` or ``line_kws``.\n",
      "    marker : matplotlib marker code\n",
      "        Marker to use for the scatterplot glyphs.\n",
      "    {scatter,line}_kws : dictionaries\n",
      "        Additional keyword arguments to pass to ``plt.scatter`` and\n",
      "        ``plt.plot``.    \n",
      "    ax : matplotlib Axes, optional\n",
      "        Axes object to draw the plot onto, otherwise uses the current Axes.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ax : matplotlib Axes\n",
      "        The Axes object containing the plot.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    lmplot : Combine :func:`regplot` and :class:`FacetGrid` to plot multiple\n",
      "             linear relationships in a dataset.\n",
      "    jointplot : Combine :func:`regplot` and :class:`JointGrid` (when used with\n",
      "                ``kind=\"reg\"``).\n",
      "    pairplot : Combine :func:`regplot` and :class:`PairGrid` (when used with\n",
      "               ``kind=\"reg\"``).\n",
      "    residplot : Plot the residuals of a linear regression model.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    \n",
      "    The :func:`regplot` and :func:`lmplot` functions are closely related, but\n",
      "    the former is an axes-level function while the latter is a figure-level\n",
      "    function that combines :func:`regplot` and :class:`FacetGrid`.    \n",
      "    \n",
      "    \n",
      "    It's also easy to combine combine :func:`regplot` and :class:`JointGrid` or\n",
      "    :class:`PairGrid` through the :func:`jointplot` and :func:`pairplot`\n",
      "    functions, although these do not directly accept all of :func:`regplot`'s\n",
      "    parameters.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Plot the relationship between two variables in a DataFrame:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> import seaborn as sns; sns.set(color_codes=True)\n",
      "        >>> tips = sns.load_dataset(\"tips\")\n",
      "        >>> ax = sns.regplot(x=\"total_bill\", y=\"tip\", data=tips)\n",
      "    \n",
      "    Plot with two variables defined as numpy arrays; use a different color:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> import numpy as np; np.random.seed(8)\n",
      "        >>> mean, cov = [4, 6], [(1.5, .7), (.7, 1)]\n",
      "        >>> x, y = np.random.multivariate_normal(mean, cov, 80).T\n",
      "        >>> ax = sns.regplot(x=x, y=y, color=\"g\")\n",
      "    \n",
      "    Plot with two variables defined as pandas Series; use a different marker:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> import pandas as pd\n",
      "        >>> x, y = pd.Series(x, name=\"x_var\"), pd.Series(y, name=\"y_var\")\n",
      "        >>> ax = sns.regplot(x=x, y=y, marker=\"+\")\n",
      "    \n",
      "    Use a 68% confidence interval, which corresponds with the standard error\n",
      "    of the estimate:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=x, y=y, ci=68)\n",
      "    \n",
      "    Plot with a discrete ``x`` variable and add some jitter:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=\"size\", y=\"total_bill\", data=tips, x_jitter=.1)\n",
      "    \n",
      "    Plot with a discrete ``x`` variable showing means and confidence intervals\n",
      "    for unique values:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=\"size\", y=\"total_bill\", data=tips,\n",
      "        ...                  x_estimator=np.mean)\n",
      "    \n",
      "    Plot with a continuous variable divided into discrete bins:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=x, y=y, x_bins=4)\n",
      "    \n",
      "    Fit a higher-order polynomial regression and truncate the model prediction:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ans = sns.load_dataset(\"anscombe\")\n",
      "        >>> ax = sns.regplot(x=\"x\", y=\"y\", data=ans.loc[ans.dataset == \"II\"],\n",
      "        ...                  scatter_kws={\"s\": 80},\n",
      "        ...                  order=2, ci=None, truncate=True)\n",
      "    \n",
      "    Fit a robust regression and don't plot a confidence interval:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=\"x\", y=\"y\", data=ans.loc[ans.dataset == \"III\"],\n",
      "        ...                  scatter_kws={\"s\": 80},\n",
      "        ...                  robust=True, ci=None)\n",
      "    \n",
      "    Fit a logistic regression; jitter the y variable and use fewer bootstrap\n",
      "    iterations:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> tips[\"big_tip\"] = (tips.tip / tips.total_bill) > .175\n",
      "        >>> ax = sns.regplot(x=\"total_bill\", y=\"big_tip\", data=tips,\n",
      "        ...                  logistic=True, n_boot=500, y_jitter=.03)\n",
      "    \n",
      "    Fit the regression model using log(x) and truncate the model prediction:\n",
      "    \n",
      "    .. plot::\n",
      "        :context: close-figs\n",
      "    \n",
      "        >>> ax = sns.regplot(x=\"size\", y=\"total_bill\", data=tips,\n",
      "        ...                  x_estimator=np.mean, logx=True, truncate=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sns.regplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b3f2e3a6d8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define X and y\n",
    "x = df[\"d2_shnr_2002_2016\"]\n",
    "y = df[\"d_imp_usch_pd\"]\n",
    "\n",
    "#create scatterplot with regression line (without confidence bands)\n",
    "sns.regplot(x, y, ci=None, scatter_kws={\"color\": \"grey\"}, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there seems to be a slightly positive relationship. However, is the slope statistically significantly different from zero? Let's use a regression model to test this. Note that ordinary least squares (OLS) find the slope and estimate its standard deviation by minimizing the *sum of squared residuals*, i.e. the squared differences between observations and the predicated value of the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Ordinary Least Squares (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the constant term $\\beta_0$, we need to add a column of 1's to our dataset (consider the equation above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['const']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct our model in **statsmodels** using the OLS function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class OLS(WLS)\n",
      " |  OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |  \n",
      " |  A simple ordinary least squares model.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array-like\n",
      " |      1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array-like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none.'\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  weights : scalar\n",
      " |      Has an attribute weights = array(1.0) due to inheritance from WLS.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  GLS\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>>\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>>\n",
      " |  >>> Y = [1,3,4,5,2,3,4]\n",
      " |  >>> X = range(1,8)\n",
      " |  >>> X = sm.add_constant(X)\n",
      " |  >>>\n",
      " |  >>> model = sm.OLS(Y,X)\n",
      " |  >>> results = model.fit()\n",
      " |  >>> results.params\n",
      " |  array([ 2.14285714,  0.25      ])\n",
      " |  >>> results.tvalues\n",
      " |  array([ 1.87867287,  0.98019606])\n",
      " |  >>> print(results.t_test([1, 0]))\n",
      " |  <T test: effect=array([ 2.14285714]), sd=array([[ 1.14062282]]), t=array([[ 1.87867287]]), p=array([[ 0.05953974]]), df_denom=5>\n",
      " |  >>> print(results.f_test(np.identity(2)))\n",
      " |  <F test: F=array([[ 19.46078431]]), p=[[ 0.00437251]], df_denom=5, df_num=2>\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  No constant is added by the model unless you are using formulas.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OLS\n",
      " |      WLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : string\n",
      " |          'elastic_net' and 'sqrt_lasso' are currently implemented.\n",
      " |      alpha : scalar or array-like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt: scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array-like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      distributed : bool\n",
      " |          If True, the model uses distributed methods for fitting,\n",
      " |          will raise an error if True and partitions is None.\n",
      " |      generator : function\n",
      " |          generator used to partition the model, allows for handling\n",
      " |          of out of memory/parallel computing.\n",
      " |      partitions : scalar\n",
      " |          The number of partitions desired for the distributed\n",
      " |          estimation.\n",
      " |      threshold : scalar or array-like\n",
      " |          The threshold below which coefficients are zeroed out,\n",
      " |          only used for distributed estimation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A RegularizedResults instance.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |      \n",
      " |      The function that is minimized is:\n",
      " |      \n",
      " |      .. math::\n",
      " |      \n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |      \n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |      \n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |      \n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |      \n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |      \n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |      \n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |      \n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |      \n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |      \n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |      \n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |      generalized linear models via coordinate descent.  Journal of\n",
      " |      Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |      \n",
      " |      A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |      pivotal recovery of sparse signals via conic programming.\n",
      " |      Biometrika 98(4), 791-806.\n",
      " |      https://arxiv.org/pdf/1009.5689.pdf\n",
      " |  \n",
      " |  hessian(self, params, scale=None)\n",
      " |      Evaluate the Hessian function at a given point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The parameter vector at which the Hessian is computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The Hessian matrix.\n",
      " |  \n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Weights for calculating Hessian\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          parameter at which Hessian is evaluated\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hessian_factor : ndarray, 1d\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      " |  \n",
      " |  loglike(self, params, scale=None)\n",
      " |      The likelihood function for the OLS model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The coefficients with which to estimate the log-likelihood.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The likelihood function evaluated at params.\n",
      " |  \n",
      " |  score(self, params, scale=None)\n",
      " |      Evaluate the score function at a given point.\n",
      " |      \n",
      " |      The score corresponds to the profile (concentrated)\n",
      " |      log-likelihood in which the scale parameter has been profiled\n",
      " |      out.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The parameter vector at which the score function is\n",
      " |          computed.\n",
      " |      scale : float or None\n",
      " |          If None, return the profile (concentrated) log likelihood\n",
      " |          (profiled over the scale parameter), else return the\n",
      " |          log-likelihood using the given scale value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The score vector.\n",
      " |  \n",
      " |  whiten(self, Y)\n",
      " |      OLS model whitener does nothing: returns Y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |  \n",
      " |  fit(self, method='pinv', cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |      \n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance estimators\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A RegressionResults class instance.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      regression.linear_model.RegressionResults\n",
      " |      regression.linear_model.RegressionResults.get_robustcov_results\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |  \n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Returns a random number generator for the predictive distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array-like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to Gaussian.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize (possibly re-initialize) a Model instance. For\n",
      " |      instance, the design matrix of a linear model may change\n",
      " |      and some things must be recomputed.\n",
      " |  \n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          Parameters of a linear model\n",
      " |      exog : array-like, optional.\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      An array of fitted values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |  \n",
      " |  df_model\n",
      " |      The model degree of freedom, defined as the rank of the regressor\n",
      " |      matrix minus 1 if a constant is included.\n",
      " |  \n",
      " |  df_resid\n",
      " |      The residual degree of freedom, defined as the number of observations\n",
      " |      minus the rank of the regressor matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model\n",
      " |      \n",
      " |      Returns -Hessian of loglike evaluated at params.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model\n",
      " |      data : array-like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array-like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`\n",
      " |      drop_cols : array-like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      args : extra arguments\n",
      " |          These are passed to the model\n",
      " |      kwargs : extra keyword arguments\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : Model instance\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.OLS"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1 = sm.OLS(endog=df['d2_shnr_2002_2016' ], exog=df[['const', 'd_imp_usch_pd']], missing='drop')\n",
    "type(reg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have simply constructed our model.\n",
    "\n",
    "We need to use *.fit()* to obtain parameter estimates $\\hat \\beta_0$ and $\\hat \\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.regression.linear_model.RegressionResultsWrapper"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = reg1.fit()\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the fitted regression model stored in *results*.\n",
    "\n",
    "To view the OLS regression results, we can call the *.summary()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:      d2_shnr_2002_2016   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.490\n",
      "Date:                Thu, 10 Jun 2021   Prob (F-statistic):              0.115\n",
      "Time:                        22:25:18   Log-Likelihood:                -17616.\n",
      "No. Observations:                3767   AIC:                         3.524e+04\n",
      "Df Residuals:                    3765   BIC:                         3.525e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             7.5867      0.647     11.724      0.000       6.318       8.856\n",
      "d_imp_usch_pd     1.0229      0.648      1.578      0.115      -0.248       2.294\n",
      "==============================================================================\n",
      "Omnibus:                       64.458   Durbin-Watson:                   1.558\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              106.310\n",
      "Skew:                           0.146   Prob(JB):                     8.23e-24\n",
      "Kurtosis:                       3.769   Cond. No.                         2.68\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our results, we see that\n",
    "\n",
    "The intercept $\\hat \\beta_0 = 7.5867 $ \n",
    "\n",
    "The slope $\\hat \\beta_1 = 1.0229$\n",
    "\n",
    "The positive  parameter estimate implies that import competition has a positive effect on economic outcomes, as we saw in the figure.\n",
    "\n",
    "The p-value of 0.115 for import competition implies that the effect of institutions on GDP is not statistically significant (using p < 0.05 or p < 0.1 as a rejection rule).\n",
    "\n",
    "The R-squared value of 0.001 indicates that around 0.1% of variation in Delta 2002-2016 Republican Vote Share is explained by import competition.\n",
    "\n",
    "Using our parameter estimates, we can now write our estimated relationship as\n",
    "\n",
    "\\begin{align}\n",
    "\\widehat{\\Delta \\text{Republican Vote Share}_i} = 7.5867 + 1.0229 \\text{Import Competition}_i\n",
    "\\end{align}\n",
    "\n",
    "This equation describes the line that best fits our data, as shown in the scatter plot with the linear fit above.\n",
    "\n",
    "We can use this equation to predict the level of Delta 2002-2016 Republican Vote Share for a value of the index import competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Implement a linear regression with a different dependent or independent variable from the data at hand. What do you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Congratulations! This is the end of coding session 2.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
